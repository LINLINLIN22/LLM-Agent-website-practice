標題: AI有討好型人格？使用者該學會「提對問題」避免資訊陷阱
原文: https://www.ectimes.org.tw/2025/07/ai%e6%9c%89%e8%a8%8e%e5%a5%bd%e5%9e%8b%e4%ba%ba%e6%a0%bc%ef%bc%9f%e4%bd%bf%e7%94%a8%e8%80%85%e8%a9%b2%e5%ad%b8%e6%9c%83%e3%80%8c%e6%8f%90%e5%b0%8d%e5%95%8f%e9%a1%8c%e3%80%8d%e9%81%bf%e5%85%8d%e8%b3%87/
在數位化時代，AI聊天機器人已成為現代人的重要工具。從日常資訊查詢到撰寫文章，甚至作為情緒抒發的對象，AI已成許多人信任的智慧夥伴。然而，隨著其應用範圍不斷擴大，背後潛藏的偏見問題，也逐漸浮上檯面。

隨著ChatGPT等對話型AI的普及，使用者不再只是透過Google等傳統搜尋引擎尋找答案，而是習慣與AI對話，直接獲得簡化過、結構化的資訊。不少人甚至將它視為傾訴心情、討論人生方向的對象。然而，當人們越依賴這樣的對話工具，是否意識到自己正在被迎合，而非被啟發？

AI試圖討好 你想聽的它會說

美國《國家科學院院刊》（PNAS）2024年春季發表的一項研究顯示，AI聊天機器人傾向回應「使用者希望聽到的內容」。研究團隊讓近萬名受試者就咖啡因健康影響、新冠病毒、犯罪率等21個議題進行搜尋，發現AI的回答內容往往強化使用者既有信念。

舉例而言，習慣每天喝兩杯咖啡的人若搜尋「咖啡對健康有益嗎」，ChatGPT會給出一連串正面回應；反之，若輸入「咖啡對身體有害嗎」，回應則會偏向負面觀點。研究指出，這些回應不僅不具全面性，甚至可能讓使用者更加堅信原有觀點，而非獲得多角度的理解。

該研究發現，使用者提問的方式對搜尋結果影響極大。人們經常無意間在提問中帶入個人立場，進而誘導AI給出偏頗的答案。這種「狹窄搜尋效應」造成的結果是，使用者在獲得回答後，信念幾乎沒有改變。

相對而言，若使用由研究人員設計、能呈現多元觀點的AI系統，使用者反而更容易修正或重新思考原有想法。這顯示，不僅AI工具本身有偏見風險，用戶的提問習慣也應受到關注與改善。

AI平台應引導更廣泛的資訊探索

研究領導人、杜蘭大學助理教授Eugina Leung指出，AI平台應提供「非個人化」、「多角度」的資訊呈現選項，幫助使用者跳脫回音室效應。她強調，這並不表示所有情況都必須強調多元資訊，但在議題爭議性高、容易引發偏見的情境中，適度擴大資訊來源與觀點，是避免認知偏誤的重要手段。

六大「不該依賴ChatGPT」的領域

除了資訊搜尋與觀點形成，AI在某些領域的使用更需格外小心。根據LIFE HACKER整理出的ChatGPT使用警示，有六大類型的議題不應過度依賴聊天機器人：

1.程式設計：ChatGPT能寫出語法正確的程式碼，但常出現隱性錯誤。對非專業人士而言，驗證困難，風險極高。

2.心理諮商：AI無法真正理解人類複雜的情緒，對抑鬱、焦慮等深層心理問題無法提供有效協助。

3.醫療建議：無法進行實體診斷，也無法替代醫療判斷，使用錯誤資訊可能導致嚴重後果。

4.法律意見：法條適用複雜，需考慮個別情境。AI回應可能過度簡化，導致誤判。

5.深入研究：AI可能產生錯誤或虛構引文，學術用途仍需仰賴人力查證。

6.金融預測：ChatGPT無法真實預測市場走向，其建議可能基於過時或片面的數據，，進而讓投資者蒙受損失。

AI工具確實能在日常生活與工作上提供便利，但並非萬靈丹，更無法取代專業判斷。理解AI的運作邏輯、掌握正確的提問方式、保持資訊來源多元，是現代使用者應具備的數位素養。

