標題: 蘋果計劃透過小型語言模型推進未來AI策略
原文: https://www.ectimes.org.tw/2024/07/%e8%98%8b%e6%9e%9c%e8%a8%88%e5%8a%83%e9%80%8f%e9%81%8e%e5%b0%8f%e5%9e%8b%e8%aa%9e%e8%a8%80%e6%a8%a1%e5%9e%8b%e6%8e%a8%e9%80%b2%e6%9c%aa%e4%be%86ai%e7%ad%96%e7%95%a5/
資料來源：Linkedin

開放式、小型模型正受到矚目

蘋果以其軟體和硬體的整合而聞名，該公司最近一直在分享有關其機器學習模型的資訊和程式碼，其最新版本「OpenELM」是小型語言模型 (SLM)，用於在記憶體受限的裝置上運行，蘋果尚未透露其生成式人工智慧策略，但一切都表明它試圖主導尚未蓬勃發展的設備上人工智慧市場，而且該市場潛力可能大到足以讓蘋果擺脫一貫的保密文化，雖然 Apple 並不是唯一一發展SLM 的公司，但它有也許有幾個因素可以發揮其優勢。

蘋果策略發展方向（資料來源：CB Insight）

事實上，在過去的一年裡，開放模型取得了令人矚目的進步。運行它們的成本只是私有模型的一小部分，而且它們的性能正在迅速趕上，但更重要的是，開放模型使研究界能夠將其重新用於新的應用和環境，例如在發布後的幾天內，Meta 的 Llama 3已經進行數千種和修改。

什麼是 OpenELM？

OpenELM 是一系列在公開資料集上進行預先訓練和微調的語言模型，模型有四種大小，參數範圍從 2.7 億到 30 億不等，能夠輕鬆在筆記型電腦和手機上運行，實測指出，OpenELM 模型的性能明顯優於其他類似規模的 SLM。 OpenELM 的一個突出特點是其非均勻結構，Transformer 模型被設計為跨層和區塊具有相同的配置。雖然這使得架構更易於管理，但它導致模型無法有效地分配參數，與這些模型不同，OpenELM 中的每個 Transformer 層都有不同的配置，例如注意力頭的數量和前饋網路的維度，這使得架構更加複雜，但使 OpenELM 能夠更好地利用可用的參數預算來獲得更高的精度。

OpenELM 的主要特點是其資源效率，其原理原則是在給定有限的資源（例如記憶體和計算）的情況下獲得性能最佳的模型。

蘋果的設備端人工智慧策略

雖然蘋果不具備微軟或Google等超大規模企業的優勢，但在設備端推理方面，它確實具有優勢，蘋果對其設備的軟體和硬體擁有完全的控制權，因此，它可以為其處理器優化其模型，也可以為其模型優化下一代處理器，這就是為什麼 Apple 發布的每款型號都包含針對 Apple優化的版本；同時，開放這些模型將刺激研究人員的活動，這可以產生網路效應，使Apple設備在設備上AI方面具有優勢，吸引更多開發者為Apple生態系統創建SLM應用程式，並使Apple能夠更好地了解如何優化其下一代硬體和軟體。

但蘋果也將面臨其他公司的競爭，其中包括微軟，微軟在小語言模型上投入大量資金，並正在建立一個在設備和雲端無縫運行的人工智慧副駕駛生態系統，誰將成為生成式人工智慧市場的最終贏家，是否會出現與許多主導企業平行的市場，還有待觀察。

