標題: 企業禁止使用生成式AI　微軟將推出私有版Chat GPT？
原文: https://www.ectimes.org.tw/2023/05/%e4%bc%81%e6%a5%ad%e7%a6%81%e6%ad%a2%e4%bd%bf%e7%94%a8%e7%94%9f%e6%88%90%e5%bc%8fai%e3%80%80%e5%be%ae%e8%bb%9f%e5%b0%87%e6%8e%a8%e5%87%ba%e7%a7%81%e6%9c%89%e7%89%88chat-gpt%ef%bc%9f/
隨著OpenAI所推出的ChatGPT爆紅後，許多企業的員工也紛紛將工作上的問題求助於像ChatGPT這類的生成式AI，以尋求最佳解答，但這也衍生出了資安方面的問題，不斷地傳出機密資料外洩的災情，為了消弭這樣的情況，據傳微軟將推出私有版的Chat GPT，利用其專業的雲端技術，將特殊族群用戶的資料獨立保存，以防資料外洩。

ChatGPT風行後，全球各地不斷地傳出資料外洩地災情，據資料安全服務公司Cyberhaven於今年三月份某一週針對旗下產品的用戶進行監測統計，發現平均每10萬名員工就會出現199次機密文件外流，其中以顧客資料、程式原始碼等資料外洩最為大宗，顯現出在ChatGPT出現後，許多企業的員工已經十分倚賴它，並將它做為工作上的工具，然而卻也忽略了背後所帶來的資安風險。

也因此，許多企業都明令禁止員工在工作中使用ChatGPT這類的生成式AI，如三星電子禁止員工在自家公司的內部網路以及各項設備使用ChatGPT和Bard、Bing等生成式AI。除此之外，三星電子也告訴員工，在自己的個人設備使用生成式AI時，不要洩漏公司相關的資訊，否則最重會遭到解雇處分。除了三星以外，其他企業如摩根大通、花旗等銀行早也禁止員工使用。

面對這樣的情況，據傳，微軟的Azure雲端服務部門計畫打造「私有版ChatGPT」，利用其雲端伺服器儲存特定用戶的資訊，但價格可能也是現有付費版的10倍以上。未來私有版ChatGPT的動向以及市場發展，十分令人好奇。

