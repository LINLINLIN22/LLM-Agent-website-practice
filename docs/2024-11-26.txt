標題: Meta 開源模型 Llama 被共軍用來開發 AI 工具？！
原文: https://www.ectimes.org.tw/2024/11/meta-%e9%96%8b%e6%ba%90%e6%a8%a1%e5%9e%8b-llama-%e8%a2%ab%e5%85%b1%e8%bb%8d%e7%94%a8%e4%be%86%e9%96%8b%e7%99%bc-ai-%e5%b7%a5%e5%85%b7%ef%bc%9f%ef%bc%81/
由Meta所開發的大型語言模型(Large language model，LLM) 「Llama」，擅長處理和生成人類語言，能完成翻譯、寫作、問答等多種任務，此外，Llama更是一個開源模型，可以提供給程式撰寫人員自由運用，也為了大型語言模型技術發展帶來了新的突破。然而，卻傳出此開源模型遭到中共軍方使用，開發出了應用於軍事方面的 AI 工具。

美國國防政策智庫發現，在一篇論文中，有隸屬於中國研究機構以及解放軍機構的研究人員，介紹了他們使用Llama開發出的「ChatBIT」。ChatBIT 是一個被設計來回答軍事問題的 AI 工具，經過了中國研究人員進行參數的微調，性能優於市面上的ChatGPT-4等 AI 模型，可以為作戰相關問題提供精準回覆。

然而，此舉已違反 Meta 的限制了，為了避免模型被濫用，Meta 規定其開源模型不得應用於軍事、戰爭、核工業、間諜活動等領域，也不得用於開發武器或製造煽動暴力的內容。這些限制符合美國的國防出口管制規定。而中共開發 ChatBIT 並未獲得 Meta 的授權，Meta 以及美國方面嚴厲譴責此行為，然而中共方面並未對此事多做回應。

由 Meta Llama 事件可以讓我們發現，AI 技術的發展是一把雙刃劍，為人類社會帶來進步和便利的同時，也帶來了一系列的挑戰和風險。因此應該要去思考該如何避免此狀況的發生，而當狀況發生時，Meta 方又該如何處理，才能有效防止狀況持續發生。

