標題: 資策會MIC研究指出   全球AI治理監管框架漸趨具體化
原文: https://www.ectimes.org.tw/2024/04/%e8%b3%87%e7%ad%96%e6%9c%83mic%e7%a0%94%e7%a9%b6%e6%8c%87%e5%87%ba-%e5%85%a8%e7%90%83ai%e6%b2%bb%e7%90%86%e7%9b%a3%e7%ae%a1%e6%a1%86%e6%9e%b6%e6%bc%b8%e8%b6%a8%e5%85%b7%e9%ab%94%e5%8c%96/
AI科技日異月新，也帶來不少資安危機，資策會產業情報研究所MIC今天(17日)指出，黑帽駭客可以利⽤AI快速學習技術，提升內容的說服⼒，但全球AI治理監管框架漸趨具體化。

資策會產業情報研究所MIC資深產業分析師徐暐釗17日於《37th MIC FORUM Spring 智賦》研討會上指出，⽣成式AI強化了DeepFake(深偽技術)⽣成内容的速度和品質，提升了內容的說服⼒，2023年前5名的⾝份詐欺類型包括⼈⼯智慧詐欺、⾦錢洗錢網路、假⾝分證、帳⼾接管和強制驗證。

他觀察⽬前駭客應⽤AI是輔助性質，影響較⼤為網路釣⿂與DeepFake攻擊，對其它攻擊尚未出現質變性的影響，但駭客可以利⽤AI快速學習技術與服務內容，加速了整體攻擊威脅進展。他說：『(原音)在資訊搜集這塊呢，就是駭客在攻擊時，一開始需要搜集攻擊目標的一些初階資訊，不管是人或是網路環境，生成式AI可以大幅縮短搜集時間。』

不過，他也提到，全球AI治理監管框架漸趨具體化，目前全球或地區已經有195個AI監管的倡議、280個國家戰略議程、78個資料管理和存取的倡議，要求企業需制定各種策略、流程以產出滿⾜法規要求的評測、透明度報告，攻擊偵測、弱點管理等技術⾯向，也推動了AI資安的新創公司發展⽅向。

徐暐釗強調，目前資安最大弱點是「人」，當AI越來越強，人類也給了他更大權限，當掌控越來越低，未來發生資安危機時，人類可能插手不了，這是需要被思考的議題。

