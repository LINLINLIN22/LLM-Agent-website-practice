標題: 從冷冰冰到暖呼呼 不同類型的AI人格正改變人機互動方式
原文: https://www.ectimes.org.tw/2025/05/%e5%be%9e%e5%86%b7%e5%86%b0%e5%86%b0%e5%88%b0%e6%9a%96%e5%91%bc%e5%91%bc-%e4%b8%8d%e5%90%8c%e9%a1%9e%e5%9e%8b%e7%9a%84ai%e4%ba%ba%e6%a0%bc%e6%ad%a3%e6%94%b9%e8%ae%8a%e4%ba%ba%e6%a9%9f%e4%ba%92/
在人工智慧的快速發展中，聊天機器人（Chatbot）已不僅僅是冷冰冰的工具，它們的「人格」特質逐漸成為使用者互動與信任的關鍵。近期，學術界針對大型語言模型（LLM）進行了深入研究，揭示了不同AI在倫理判斷、人格表現與價值觀對齊方面的差異。其中，GPT-4.5整體穩定性佳，展現出自我導向與親切仁慈的特質；DeepSeek-V3則是其中最遵循規則者，靈活度較低；Llama則喜愛腦力激盪、自主行動能力強，較適用於自由發想的情境中。

根據《PersonaLLM》研究，GPT-3.5與GPT-4在模擬人格特質方面表現出色。 研究人員為這些模型賦予了基於大五人格理論（Big Five）的性格設定，並讓其完成相應的心理測評與寫作任務。結果顯示，這些AI能夠在語言表達中展現出與其人格設定一致的特徵，且人類評審能以高達80%的準確率識別其人格特質。此外，GPT-4在一項行為測試中，展現出與人類相似的信任、公平與合作行為，甚至在某些情境下更具利他性。這代表著AI於特定情境下，居然可以模擬出人類的社會行為

而在倫理判斷方面，GPT-4.5與Claude 3.5 Sonnet的表現存在顯著差異。根據《Bias in Decision-Making for AI’s Ethical Dilemmas》的研究中顯示，GPT-4.5在面對涉及年齡、性別、種族等敏感議題時，傾向於遵循傳統的權力結構，顯示出一定的偏見。相對而言，Claude 3.5則展現出更為多元的選擇，顯示出較高的倫理敏感度。然而，當情境中涉及多重保護屬性時，兩者的倫理敏感度均顯著下降，顯示出在複雜情境下，AI的倫理判斷仍存在挑戰。

AI的「價值對齊」問題一直是業界與學界關注的焦點。以ChatGPT為例，OpenAI採用了「人類反饋強化學習（RLHF）」的訓練方式，旨在使AI的行為與人類的價值觀保持一致。然而，這種訓練方式是否能真正實現全球範圍內的價值對齊，仍存在疑問。不同文化與社會背景下的人類價值觀存在差異，AI如何在這些差異中找到平衡點，仍存在著許多挑戰。隨著AI模型深化進大眾的日常情境中，未來模型應持續強化價值的多元性與安全性，避免出現單一立場與視角偏頗互動。

